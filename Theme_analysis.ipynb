{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juli1001/Introduction-To-Numpy/blob/main/Theme_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "F3BVy-Ev0o8n",
        "outputId": "a15b0407-960f-46d4-e477-cfea7401b9d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.3-py3-none-any.whl (327 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/327.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/327.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m317.4/327.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "import openai\n",
        "import pandas as pd\n",
        "import time\n",
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key='###')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_ndba0f1Edm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UVMpINloR_1"
      },
      "source": [
        "# **Data Frame from data base**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vkq7mmGp1qkU",
        "outputId": "0b400576-1c48-48a6-eb7e-bae359afca20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mysql-connector-python\n",
            "  Downloading mysql_connector_python-8.4.0-cp310-cp310-manylinux_2_17_x86_64.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mysql-connector-python\n",
            "Successfully installed mysql-connector-python-8.4.0\n",
            "Collecting plotly==5.3.1\n",
            "  Downloading plotly-5.3.1-py2.py3-none-any.whl (23.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.9/23.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly==5.3.1) (8.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from plotly==5.3.1) (1.16.0)\n",
            "Installing collected packages: plotly\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.15.0\n",
            "    Uninstalling plotly-5.15.0:\n",
            "      Successfully uninstalled plotly-5.15.0\n",
            "Successfully installed plotly-5.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mysql-connector-python\n",
        "!pip install plotly==5.3.1\n",
        "from sqlalchemy import create_engine, text\n",
        "connection_string = \"mysql+mysqlconnector://####\"\n",
        "engine = create_engine(connection_string, echo=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uC_sNrLA1OpT",
        "outputId": "aaa23a37-a649-4684-9374-002c9a4de919"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-06-24 19:55:15,961 INFO sqlalchemy.engine.Engine SELECT DATABASE()\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sqlalchemy.engine.Engine:SELECT DATABASE()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-06-24 19:55:15,963 INFO sqlalchemy.engine.Engine [raw sql] {}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sqlalchemy.engine.Engine:[raw sql] {}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-06-24 19:55:16,679 INFO sqlalchemy.engine.Engine SELECT @@sql_mode\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sqlalchemy.engine.Engine:SELECT @@sql_mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-06-24 19:55:16,681 INFO sqlalchemy.engine.Engine [raw sql] {}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sqlalchemy.engine.Engine:[raw sql] {}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-06-24 19:55:17,040 INFO sqlalchemy.engine.Engine SELECT @@lower_case_table_names\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sqlalchemy.engine.Engine:SELECT @@lower_case_table_names\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-06-24 19:55:17,042 INFO sqlalchemy.engine.Engine [raw sql] {}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sqlalchemy.engine.Engine:[raw sql] {}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-06-24 19:55:17,578 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sqlalchemy.engine.Engine:BEGIN (implicit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-06-24 19:55:17,583 INFO sqlalchemy.engine.Engine SELECT l.assistant_name, l.business_name,c.status, c.from ,c.start_datetime, c.end_datetime, c.listing_id AS conversation_listing_id, c.id_channel, TIMESTAMPDIFF(MINUTE, c.start_datetime, c.end_datetime) AS conversation_duration, TIME_TO_SEC(TIMEDIFF(c.end_datetime, c.start_datetime)) / 60 AS conversation_duration_minutes, CASE c.id_channel WHEN 1 THEN 'voice' WHEN 2 THEN 'text' WHEN 3 THEN 'whatsapp' ELSE 'otros' END AS channel_name, c.messages FROM AI_HELLOU_DB.listing AS l JOIN AI_HELLOU_DB.conversation AS c ON l.id = c.listing_id;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sqlalchemy.engine.Engine:SELECT l.assistant_name, l.business_name,c.status, c.from ,c.start_datetime, c.end_datetime, c.listing_id AS conversation_listing_id, c.id_channel, TIMESTAMPDIFF(MINUTE, c.start_datetime, c.end_datetime) AS conversation_duration, TIME_TO_SEC(TIMEDIFF(c.end_datetime, c.start_datetime)) / 60 AS conversation_duration_minutes, CASE c.id_channel WHEN 1 THEN 'voice' WHEN 2 THEN 'text' WHEN 3 THEN 'whatsapp' ELSE 'otros' END AS channel_name, c.messages FROM AI_HELLOU_DB.listing AS l JOIN AI_HELLOU_DB.conversation AS c ON l.id = c.listing_id;\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-06-24 19:55:17,592 INFO sqlalchemy.engine.Engine [generated in 0.19145s] {}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sqlalchemy.engine.Engine:[generated in 0.19145s] {}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     assistant_name                           structured_conversations\n",
            "0             Julia  User: alumina service  made when I started are...\n",
            "1             Julia       User:  \\nUser: Columbia.\\nUser: Will change.\n",
            "2             Julia                            User: same with that is\n",
            "3             Julia  User: When I saw this.  even when I start a nu...\n",
            "4             Julia  User:  Hello Mrs.\\nAsistente: Koury, I am inte...\n",
            "...             ...                                                ...\n",
            "2274   Green Tomato  User: Tienes tomates earloom?\\nAsistente: Sí, ...\n",
            "2275   Green Tomato  User: Test 2\\nAsistente: Hello! How can I assi...\n",
            "2276   Green Tomato  User: hola… que vegetales tienes?\\nAsistente: ...\n",
            "2277   Green Tomato  User: Yes, I would like to know if you deliver...\n",
            "2278   Green Tomato  User: hello\\nAsistente: Hello! How can I assis...\n",
            "\n",
            "[2279 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "result = engine.connect().execute(text(\"SELECT l.assistant_name, l.business_name,c.status, c.from ,c.start_datetime, c.end_datetime, c.listing_id AS conversation_listing_id, c.id_channel, TIMESTAMPDIFF(MINUTE, c.start_datetime, c.end_datetime) AS conversation_duration, TIME_TO_SEC(TIMEDIFF(c.end_datetime, c.start_datetime)) / 60 AS conversation_duration_minutes, CASE c.id_channel WHEN 1 THEN 'voice' WHEN 2 THEN 'text' WHEN 3 THEN 'whatsapp' ELSE 'otros' END AS channel_name, c.messages FROM AI_HELLOU_DB.listing AS l JOIN AI_HELLOU_DB.conversation AS c ON l.id = c.listing_id;\"))\n",
        "data = [tuple(row) for row in result]\n",
        "columns = result.keys()\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "# Parsea la cadena JSON en la columna \"messages\"\n",
        "df['messages'] = df['messages'].apply(lambda x: json.loads(x))\n",
        "\n",
        "# Crear una nueva columna con las conversaciones estructuradas\n",
        "structured_conversations = []\n",
        "for message_list in df['messages']:\n",
        "    conversation = \"\"\n",
        "    for msg in message_list:\n",
        "        role = msg['role']\n",
        "        content = msg['content']\n",
        "        if role == 'user':\n",
        "            conversation += f\"User: {content}\\n\"\n",
        "        elif role == 'assistant':\n",
        "            conversation += f\"Asistente: {content}\\n\"\n",
        "    structured_conversations.append(conversation.strip())\n",
        "\n",
        "\n",
        "df['structured_conversations'] = structured_conversations\n",
        "\n",
        "\n",
        "print(df[['assistant_name', 'structured_conversations']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9LtOdzJ1YZv"
      },
      "outputs": [],
      "source": [
        "def extraer_mensajes_usuario(texto_conversacion):\n",
        "    lineas = texto_conversacion.split('\\n')\n",
        "    mensajes_usuario = [linea for linea in lineas if linea.startswith('User:')]\n",
        "    return ' '.join(mensajes_usuario)\n",
        "\n",
        "df['mensajes_usuario'] = df['structured_conversations'].apply(extraer_mensajes_usuario)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p94Lndk53Q0b",
        "outputId": "dd1cd2cc-07a1-4274-84cc-5fc5cac88939"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: Tienes tomates earloom?\n",
            "Asistente: Sí, tenemos tomates Heirloom en nuestra selección de productos frescos. Puedes encontrarlos en nuestras bolsas de frutas y verduras mixtas. ¡Suscríbete para recibirlos en tu próxima entrega!\n",
            "User: Cuánto valen?\n",
            "Asistente: El precio de nuestras bolsas de frutas y verduras mixtas varía según el tamaño que elijas. Nuestros precios van desde $XX para la bolsa Cherry hasta $XX para la bolsa Beefsteak. Puedes encontrar más detalles sobre los precios en nuestro sitio web o contactarnos directamente para obtener información específica sobre los precios actuales.\n"
          ]
        }
      ],
      "source": [
        "print(df.iloc[2274]['structured_conversations'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "WbKmL9NFACzy",
        "outputId": "5f5d8335-46c1-44da-a1da-fc18df0b6a91"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2279,\n  \"fields\": [\n    {\n      \"column\": \"assistant_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"Julia\",\n          \"Apalachee Digital\",\n          \"Mike\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"business_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"Workcango\",\n          \"Apalachee Digital\",\n          \"Fasting & Thriving\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"COMPLETED\",\n          \"ACTIVE\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"from\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 914,\n        \"samples\": [\n          \"+59163291506\",\n          \"+18299228117\",\n          \"+593992970873\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start_datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2023-05-29 18:40:12\",\n        \"max\": \"2024-04-25 22:55:30\",\n        \"num_unique_values\": 1988,\n        \"samples\": [\n          \"2023-12-14 15:18:18\",\n          \"2023-07-13 16:09:00\",\n          \"2024-01-01 15:06:13\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end_datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2023-06-23 18:08:37\",\n        \"max\": \"2024-02-28 03:10:52\",\n        \"num_unique_values\": 956,\n        \"samples\": [\n          \"2023-09-11 17:30:49\",\n          \"2024-01-16 20:24:25\",\n          \"2023-07-13 16:44:51\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"conversation_listing_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30,\n        \"min\": 1,\n        \"max\": 172,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          74,\n          56,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id_channel\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"conversation_duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13494.9253347991,\n        \"min\": 0.0,\n        \"max\": 181731.0,\n        \"num_unique_values\": 263,\n        \"samples\": [\n          8343.0,\n          7315.0,\n          1102.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"conversation_duration_minutes\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 465,\n        \"samples\": [\n          \"0.0500\",\n          \"0.8167\",\n          \"1.9833\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"channel_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"voice\",\n          \"text\",\n          \"whatsapp\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"messages\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"structured_conversations\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1362,\n        \"samples\": [\n          \"User: Dime que se trata nuevamente, por favor.\\nAsistente: Workcango es la mayor red de contactos para emprendimientos, startups, empresas, freelancers e inversionistas en Colombia. Ofrecemos programas de estructuraci\\u00f3n de proyectos para inversi\\u00f3n, aceleraci\\u00f3n de ventas y asesor\\u00eda para cr\\u00e9ditos bancarios empresariales. \\u00bfEn qu\\u00e9 puedo ayudarte?\",\n          \"User: \\u00a1Hola! Quiero m\\u00e1s informaci\\u00f3n sobre la l\\u00ednea con whatsapp.\\nAsistente: \\u00a1Hola! Nuestro servicio de N\\u00fameros Telef\\u00f3nicos Virtuales con WhatsApp te permite tener un n\\u00famero virtual con capacidad para recibir y hacer llamadas ilimitadas a trav\\u00e9s de la aplicaci\\u00f3n WhatsApp. Tenemos opciones disponibles para Estados Unidos, Colombia y M\\u00e9xico. \\u00bfEn qu\\u00e9 pa\\u00eds est\\u00e1s interesado?\",\n          \"User: Hola\\nAsistente: \\u00a1Hola! \\u00bfEn qu\\u00e9 puedo ayudarte hoy?\\nUser: hola\\nAsistente: \\u00a1Hola! \\u00bfEn qu\\u00e9 puedo ayudarte?\\nUser: Hola\\nAsistente: \\u00a1Hola! \\u00bfEn qu\\u00e9 puedo ayudarte hoy?\\nUser: Quiero informaci\\u00f3n sobre los planes\\nAsistente: \\u00a1Claro! Estoy aqu\\u00ed para ayudarte con eso. \\u00bfEst\\u00e1s interesado en los planes de Virfon Business o los planes de Virfon Personas?\\nUser: Planes para empresas\\nAsistente: Para empresas, Virfon ofrece el servicio de Sistema Telef\\u00f3nico en la Nube (Phone System) y Contact Center en la Nube. El Sistema Telef\\u00f3nico en la Nube es una soluci\\u00f3n completa basada en la nube que te permite seleccionar un n\\u00famero telef\\u00f3nico de m\\u00e1s de 7,400 ciudades alrededor del mundo. Es ideal para trabajo remoto y tener presencia global sin inversiones costosas en equipos y servidores.\\n\\nEl Contact Center en la Nube es una soluci\\u00f3n 100% basada en la nube para soporte al cliente. Ofrece segmentaci\\u00f3n de clientes, campa\\u00f1as entrantes y salientes, m\\u00e9tricas en tiempo real y monitoreo de llamadas. Adem\\u00e1s, puedes conectar clientes y agentes desde cualquier lugar.\\n\\nSi necesitas m\\u00e1s informaci\\u00f3n sobre estos planes o deseas conocer los precios espec\\u00edficos seg\\u00fan tus necesidades empresariales, por favor proporciona tu ubicaci\\u00f3n geogr\\u00e1fica para brindarte detalles precisos.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mensajes_usuario\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1114,\n        \"samples\": [\n          \"User: \\u00a1Hola! Quiero m\\u00e1s informaci\\u00f3n sobre la l\\u00ednea para hacer y recibir llamadas. User: Nicaragua User: Gracias\",\n          \"User: Hola Mi nombre es Prix Quiero saber sobre los cr\\u00e9ditos bancarios User: C\\u00f3mo funcionan los programas\",\n          \"User: hola\\u2026 que vegetales tienes? User: y cuando pueden entregar? todos los d\\u00edas? User: Hola User: hola y puedes en cora hables? User: que vegetales? User: how about miami?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-903827b7-30b3-4a06-b237-6de72eed4fdf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>assistant_name</th>\n",
              "      <th>business_name</th>\n",
              "      <th>status</th>\n",
              "      <th>from</th>\n",
              "      <th>start_datetime</th>\n",
              "      <th>end_datetime</th>\n",
              "      <th>conversation_listing_id</th>\n",
              "      <th>id_channel</th>\n",
              "      <th>conversation_duration</th>\n",
              "      <th>conversation_duration_minutes</th>\n",
              "      <th>channel_name</th>\n",
              "      <th>messages</th>\n",
              "      <th>structured_conversations</th>\n",
              "      <th>mensajes_usuario</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Julia</td>\n",
              "      <td>Workcango</td>\n",
              "      <td>COMPLETED</td>\n",
              "      <td>+576018889232</td>\n",
              "      <td>2023-08-11 23:11:03</td>\n",
              "      <td>2023-08-11 23:12:12</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1500</td>\n",
              "      <td>voice</td>\n",
              "      <td>[{'role': 'system', 'content': ' You are engag...</td>\n",
              "      <td>User: alumina service  made when I started are...</td>\n",
              "      <td>User: alumina service  made when I started are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Julia</td>\n",
              "      <td>Workcango</td>\n",
              "      <td>COMPLETED</td>\n",
              "      <td>+576018889232</td>\n",
              "      <td>2023-08-12 22:05:33</td>\n",
              "      <td>2023-08-12 22:07:28</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.9167</td>\n",
              "      <td>voice</td>\n",
              "      <td>[{'role': 'system', 'content': ' You are engag...</td>\n",
              "      <td>User:  \\nUser: Columbia.\\nUser: Will change.</td>\n",
              "      <td>User:   User: Columbia. User: Will change.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Julia</td>\n",
              "      <td>Workcango</td>\n",
              "      <td>COMPLETED</td>\n",
              "      <td>+576018889232</td>\n",
              "      <td>2023-08-14 21:48:24</td>\n",
              "      <td>2023-08-14 21:49:11</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7833</td>\n",
              "      <td>voice</td>\n",
              "      <td>[{'role': 'system', 'content': ' You are engag...</td>\n",
              "      <td>User: same with that is</td>\n",
              "      <td>User: same with that is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Julia</td>\n",
              "      <td>Workcango</td>\n",
              "      <td>COMPLETED</td>\n",
              "      <td>+576018889232</td>\n",
              "      <td>2023-08-16 20:18:19</td>\n",
              "      <td>2023-08-16 20:19:23</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0667</td>\n",
              "      <td>voice</td>\n",
              "      <td>[{'role': 'system', 'content': ' You are engag...</td>\n",
              "      <td>User: When I saw this.  even when I start a nu...</td>\n",
              "      <td>User: When I saw this.  even when I start a nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Julia</td>\n",
              "      <td>Workcango</td>\n",
              "      <td>COMPLETED</td>\n",
              "      <td>+576018889232</td>\n",
              "      <td>2023-08-17 22:08:36</td>\n",
              "      <td>2023-08-17 22:10:06</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.5000</td>\n",
              "      <td>voice</td>\n",
              "      <td>[{'role': 'system', 'content': ' You are engag...</td>\n",
              "      <td>User:  Hello Mrs.\\nAsistente: Koury, I am inte...</td>\n",
              "      <td>User:  Hello Mrs. User: Windows 7 is going to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2274</th>\n",
              "      <td>Green Tomato</td>\n",
              "      <td>Green Tomato</td>\n",
              "      <td>COMPLETED</td>\n",
              "      <td>+19548548941</td>\n",
              "      <td>2024-02-08 16:10:17</td>\n",
              "      <td>NaT</td>\n",
              "      <td>172</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>text</td>\n",
              "      <td>[{'role': 'system', 'content': ' Ésta conversa...</td>\n",
              "      <td>User: Tienes tomates earloom?\\nAsistente: Sí, ...</td>\n",
              "      <td>User: Tienes tomates earloom? User: Cuánto valen?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2275</th>\n",
              "      <td>Green Tomato</td>\n",
              "      <td>Green Tomato</td>\n",
              "      <td>COMPLETED</td>\n",
              "      <td>+19548549333</td>\n",
              "      <td>2024-02-12 23:34:35</td>\n",
              "      <td>NaT</td>\n",
              "      <td>172</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>[{'role': 'system', 'content': ' Ésta conversa...</td>\n",
              "      <td>User: Test 2\\nAsistente: Hello! How can I assi...</td>\n",
              "      <td>User: Test 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2276</th>\n",
              "      <td>Green Tomato</td>\n",
              "      <td>Green Tomato</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>+19548548941</td>\n",
              "      <td>2024-02-22 16:11:26</td>\n",
              "      <td>NaT</td>\n",
              "      <td>172</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>text</td>\n",
              "      <td>[{'role': 'system', 'content': ' Ésta conversa...</td>\n",
              "      <td>User: hola… que vegetales tienes?\\nAsistente: ...</td>\n",
              "      <td>User: hola… que vegetales tienes? User: y cuan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2277</th>\n",
              "      <td>Green Tomato</td>\n",
              "      <td>Green Tomato</td>\n",
              "      <td>COMPLETED</td>\n",
              "      <td>+19548548941</td>\n",
              "      <td>2024-02-22 16:28:15</td>\n",
              "      <td>2024-02-22 16:28:49</td>\n",
              "      <td>172</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5667</td>\n",
              "      <td>voice</td>\n",
              "      <td>[{'role': 'system', 'content': ' Ésta conversa...</td>\n",
              "      <td>User: Yes, I would like to know if you deliver...</td>\n",
              "      <td>User: Yes, I would like to know if you deliver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2278</th>\n",
              "      <td>Green Tomato</td>\n",
              "      <td>Green Tomato</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>+19548549333</td>\n",
              "      <td>2024-02-28 03:05:36</td>\n",
              "      <td>NaT</td>\n",
              "      <td>172</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>text</td>\n",
              "      <td>[{'role': 'system', 'content': ' Ésta conversa...</td>\n",
              "      <td>User: hello\\nAsistente: Hello! How can I assis...</td>\n",
              "      <td>User: hello User: Hello User: Please let me kn...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2279 rows × 14 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-903827b7-30b3-4a06-b237-6de72eed4fdf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-903827b7-30b3-4a06-b237-6de72eed4fdf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-903827b7-30b3-4a06-b237-6de72eed4fdf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f4362eb3-4195-472d-9816-42439454702e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f4362eb3-4195-472d-9816-42439454702e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f4362eb3-4195-472d-9816-42439454702e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     assistant_name business_name     status           from  \\\n",
              "0             Julia     Workcango  COMPLETED  +576018889232   \n",
              "1             Julia     Workcango  COMPLETED  +576018889232   \n",
              "2             Julia     Workcango  COMPLETED  +576018889232   \n",
              "3             Julia     Workcango  COMPLETED  +576018889232   \n",
              "4             Julia     Workcango  COMPLETED  +576018889232   \n",
              "...             ...           ...        ...            ...   \n",
              "2274   Green Tomato  Green Tomato  COMPLETED   +19548548941   \n",
              "2275   Green Tomato  Green Tomato  COMPLETED   +19548549333   \n",
              "2276   Green Tomato  Green Tomato     ACTIVE   +19548548941   \n",
              "2277   Green Tomato  Green Tomato  COMPLETED   +19548548941   \n",
              "2278   Green Tomato  Green Tomato     ACTIVE   +19548549333   \n",
              "\n",
              "          start_datetime        end_datetime  conversation_listing_id  \\\n",
              "0    2023-08-11 23:11:03 2023-08-11 23:12:12                        1   \n",
              "1    2023-08-12 22:05:33 2023-08-12 22:07:28                        1   \n",
              "2    2023-08-14 21:48:24 2023-08-14 21:49:11                        1   \n",
              "3    2023-08-16 20:18:19 2023-08-16 20:19:23                        1   \n",
              "4    2023-08-17 22:08:36 2023-08-17 22:10:06                        1   \n",
              "...                  ...                 ...                      ...   \n",
              "2274 2024-02-08 16:10:17                 NaT                      172   \n",
              "2275 2024-02-12 23:34:35                 NaT                      172   \n",
              "2276 2024-02-22 16:11:26                 NaT                      172   \n",
              "2277 2024-02-22 16:28:15 2024-02-22 16:28:49                      172   \n",
              "2278 2024-02-28 03:05:36                 NaT                      172   \n",
              "\n",
              "      id_channel  conversation_duration conversation_duration_minutes  \\\n",
              "0              1                    1.0                        1.1500   \n",
              "1              1                    1.0                        1.9167   \n",
              "2              1                    0.0                        0.7833   \n",
              "3              1                    1.0                        1.0667   \n",
              "4              1                    1.0                        1.5000   \n",
              "...          ...                    ...                           ...   \n",
              "2274           2                    NaN                          None   \n",
              "2275           3                    NaN                          None   \n",
              "2276           2                    NaN                          None   \n",
              "2277           1                    0.0                        0.5667   \n",
              "2278           2                    NaN                          None   \n",
              "\n",
              "     channel_name                                           messages  \\\n",
              "0           voice  [{'role': 'system', 'content': ' You are engag...   \n",
              "1           voice  [{'role': 'system', 'content': ' You are engag...   \n",
              "2           voice  [{'role': 'system', 'content': ' You are engag...   \n",
              "3           voice  [{'role': 'system', 'content': ' You are engag...   \n",
              "4           voice  [{'role': 'system', 'content': ' You are engag...   \n",
              "...           ...                                                ...   \n",
              "2274         text  [{'role': 'system', 'content': ' Ésta conversa...   \n",
              "2275     whatsapp  [{'role': 'system', 'content': ' Ésta conversa...   \n",
              "2276         text  [{'role': 'system', 'content': ' Ésta conversa...   \n",
              "2277        voice  [{'role': 'system', 'content': ' Ésta conversa...   \n",
              "2278         text  [{'role': 'system', 'content': ' Ésta conversa...   \n",
              "\n",
              "                               structured_conversations  \\\n",
              "0     User: alumina service  made when I started are...   \n",
              "1          User:  \\nUser: Columbia.\\nUser: Will change.   \n",
              "2                               User: same with that is   \n",
              "3     User: When I saw this.  even when I start a nu...   \n",
              "4     User:  Hello Mrs.\\nAsistente: Koury, I am inte...   \n",
              "...                                                 ...   \n",
              "2274  User: Tienes tomates earloom?\\nAsistente: Sí, ...   \n",
              "2275  User: Test 2\\nAsistente: Hello! How can I assi...   \n",
              "2276  User: hola… que vegetales tienes?\\nAsistente: ...   \n",
              "2277  User: Yes, I would like to know if you deliver...   \n",
              "2278  User: hello\\nAsistente: Hello! How can I assis...   \n",
              "\n",
              "                                       mensajes_usuario  \n",
              "0     User: alumina service  made when I started are...  \n",
              "1            User:   User: Columbia. User: Will change.  \n",
              "2                               User: same with that is  \n",
              "3     User: When I saw this.  even when I start a nu...  \n",
              "4     User:  Hello Mrs. User: Windows 7 is going to ...  \n",
              "...                                                 ...  \n",
              "2274  User: Tienes tomates earloom? User: Cuánto valen?  \n",
              "2275                                       User: Test 2  \n",
              "2276  User: hola… que vegetales tienes? User: y cuan...  \n",
              "2277  User: Yes, I would like to know if you deliver...  \n",
              "2278  User: hello User: Hello User: Please let me kn...  \n",
              "\n",
              "[2279 rows x 14 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cLZG6-qmuBe3",
        "outputId": "83246345-a5d2-4165-bf5f-58d29559d987"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2260    User: when did you purchase this car?\\nAsisten...\n",
            "2261    User: what is special about this car?\\nAsisten...\n",
            "2262    User: Yes, who is the original owner of the ca...\n",
            "2263                                                     \n",
            "2264    User: que es un desoto?\\nAsistente: DeSoto es ...\n",
            "2265    User: Hola! Que es un DeSoto\\nAsistente: Hola!...\n",
            "2266                                                     \n",
            "2267    User: Hi there\\nAsistente: Hello! How can I as...\n",
            "2268                                                     \n",
            "2269    User:  Shayla where are you located?\\nAsistent...\n",
            "2270    User: Hi there, can you tell me more about gre...\n",
            "2271    User: WhatsApp code 584-947\\nAsistente: I apol...\n",
            "2272    User: I live in Miami Beach, when do you deliv...\n",
            "2273    User: “I got zucchini, bed bell peppers and to...\n",
            "2274    User: Tienes tomates earloom?\\nAsistente: Sí, ...\n",
            "2275    User: Test 2\\nAsistente: Hello! How can I assi...\n",
            "Name: structured_conversations, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df.iloc[2260:2276]['structured_conversations'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfzilaWioiuz"
      },
      "source": [
        "# **The theme generator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSjTdLC0_fnf",
        "outputId": "7a3c6948-6831-4423-a143-75a0295a4a97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                               structured_conversations  \\\n",
            "2260  User: when did you purchase this car?\\nAsisten...   \n",
            "2261  User: what is special about this car?\\nAsisten...   \n",
            "2262  User: Yes, who is the original owner of the ca...   \n",
            "2263                                                      \n",
            "2264  User: que es un desoto?\\nAsistente: DeSoto es ...   \n",
            "2265  User: Hola! Que es un DeSoto\\nAsistente: Hola!...   \n",
            "2266                                                      \n",
            "2267  User: Hi there\\nAsistente: Hello! How can I as...   \n",
            "2268                                                      \n",
            "2269  User:  Shayla where are you located?\\nAsistent...   \n",
            "2270  User: Hi there, can you tell me more about gre...   \n",
            "2271  User: WhatsApp code 584-947\\nAsistente: I apol...   \n",
            "2272  User: I live in Miami Beach, when do you deliv...   \n",
            "2273  User: “I got zucchini, bed bell peppers and to...   \n",
            "2274  User: Tienes tomates earloom?\\nAsistente: Sí, ...   \n",
            "2275  User: Test 2\\nAsistente: Hello! How can I assi...   \n",
            "2276  User: hola… que vegetales tienes?\\nAsistente: ...   \n",
            "2277  User: Yes, I would like to know if you deliver...   \n",
            "\n",
            "                       Theme  \n",
            "2260          family history  \n",
            "2261          Family history  \n",
            "2262       Ownership history  \n",
            "2263                     N/A  \n",
            "2264             Car History  \n",
            "2265               Car Brand  \n",
            "2266                     N/A  \n",
            "2267  Fresh Produce Delivery  \n",
            "2268                     N/A  \n",
            "2269    business information  \n",
            "2270   \\n    organic produce  \n",
            "2271        WhatsApp Support  \n",
            "2272    Subscription service  \n",
            "2273      Recipe Suggestions  \n",
            "2274     pricing information  \n",
            "2275                     N/A  \n",
            "2276       Delivery Schedule  \n",
            "2277    delivery information  \n"
          ]
        }
      ],
      "source": [
        "def analizar_Theme(conversacion):\n",
        "    prompt = f\"\"\"\n",
        "    Eres un modelo de IA entrenado para analizar el tema de las conversaciones.\n",
        "    Tu tarea es identificar el tema principal en una conversación estructurada entre un usuario y un asistente.\n",
        "\n",
        "    Ejemplo:\n",
        "    User: Tienes tomates Heirloom?\n",
        "    Asistente: Sí, tenemos tomates Heirloom en nuestra selección de productos frescos. Puedes encontrarlos en nuestras bolsas de frutas y verduras mixtas. ¡Suscríbete para recibirlos en tu próxima entrega!\n",
        "    User: Cuánto valen?\n",
        "    Asistente: El precio de nuestras bolsas de frutas y verduras mixtas varía según el tamaño que elijas. Nuestros precios van desde $XX para la bolsa Cherry hasta $XX para la bolsa Beefsteak. Puedes encontrar más detalles sobre los precios en nuestro sitio web.\n",
        "    pricing information\n",
        "\n",
        "    Analiza la siguiente conversación y determina el tema principal de la misma. El tema debe estar en inglés y ser de 2-3 palabras. Si la conversación está vacía, por favor déjalo en blanco o coloca N/A:\n",
        "\n",
        "    {conversacion['structured_conversations']}\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Eres un modelo de IA entrenado para analizar el tema de las conversaciones.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        max_tokens=4,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "\n",
        "    response_message = response.choices[0].message.content\n",
        "    return response_message\n",
        "\n",
        "# Supongamos que tu DataFrame ya está definido como df\n",
        "df_2 = df.iloc[2260:2278].copy()\n",
        "\n",
        "# Añadir columna 'Theme' al DataFrame\n",
        "df_2['Theme'] = df_2.apply(lambda row: analizar_Theme({\n",
        "    \"structured_conversations\": row['structured_conversations']\n",
        "}), axis=1)\n",
        "\n",
        "print(df_2[['structured_conversations', 'Theme']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuadtYxPo23_"
      },
      "source": [
        "# **Here I did a text (didn't work to well)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAhTctkQVm4C",
        "outputId": "eb5e8e96-9ea4-4a02-e06c-134f32bf13fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¿Qué temas quieres generar? (separados por comas) Deliveries, Business, Product, Recipe\n",
            "                               structured_conversations               Theme\n",
            "2260  User: when did you purchase this car?\\nAsisten...         Car History\n",
            "2261  User: what is special about this car?\\nAsisten...  Theme: Car History\n",
            "2262  User: Yes, who is the original owner of the ca...           Ownership\n",
            "2263                                                                    N/A\n",
            "2264  User: que es un desoto?\\nAsistente: DeSoto es ...          Automobile\n",
            "2265  User: Hola! Que es un DeSoto\\nAsistente: Hola!...         Automobiles\n",
            "2266                                                                    N/A\n",
            "2267  User: Hi there\\nAsistente: Hello! How can I as...   Delivery Services\n",
            "2268                                                                    N/A\n",
            "2269  User:  Shayla where are you located?\\nAsistent...   Delivery Services\n",
            "2270  User: Hi there, can you tell me more about gre...   Delivery Schedule\n",
            "2271  User: WhatsApp code 584-947\\nAsistente: I apol...   Delivery Services\n",
            "2272  User: I live in Miami Beach, when do you deliv...   Delivery Schedule\n",
            "2273  User: “I got zucchini, bed bell peppers and to...             Recipes\n",
            "2274  User: Tienes tomates earloom?\\nAsistente: Sí, ...     Produce Pricing\n",
            "2275  User: Test 2\\nAsistente: Hello! How can I assi...                 N/A\n",
            "2276  User: hola… que vegetales tienes?\\nAsistente: ...   Delivery Schedule\n",
            "2277  User: Yes, I would like to know if you deliver...   Delivery Schedule\n"
          ]
        }
      ],
      "source": [
        "openai.api_key='####'\n",
        "\n",
        "def analizar_Theme(conversacion, tema):\n",
        "    prompt = f\"\"\"\n",
        "    Eres un modelo de IA especializado en analizar conversaciones.\n",
        "    Tu tarea es identificar el tema principal de una conversación estructurada entre un usuario y un asistente, poniendo especial atención en lo que solicita el usuario.\n",
        "\n",
        "    Por favor, analiza la siguiente conversación y determina el tema principal en relación a \"{tema}\". El tema debe estar en inglés y ser de 1-2 palabras. Si la conversación está vacía, por favor déjalo en blanco o coloca N/A.\n",
        "\n",
        "    Ejemplo 1:\n",
        "    Conversación:\n",
        "    User: Do you have heirloom tomatoes?\n",
        "    Assistant: Yes, we have heirloom tomatoes in our fresh produce selection. You can find them in our mixed fruit and vegetable bags. Subscribe to receive them in your next delivery!\n",
        "    User: How much do they cost?\n",
        "    Assistant: The price of our mixed fruit and vegetable bags varies depending on the size you choose. Our prices range from $XX for the Cherry bag to $XX for the Beefsteak bag. You can find more details about the prices on our website.\n",
        "    Produce Pricing\n",
        "\n",
        "    Ejemplo 2:\n",
        "    Conversación:\n",
        "    User: What are your delivery hours?\n",
        "    Assistant: We deliver from 8 AM to 8 PM, Monday through Saturday.\n",
        "    User: Can you deliver on Sunday?\n",
        "    Assistant: Unfortunately, we do not deliver on Sundays.\n",
        "    Delivery Schedule\n",
        "\n",
        "    Ahora analiza la siguiente conversación:\n",
        "\n",
        "    {conversacion['structured_conversations']}\n",
        "    \"\"\"\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Eres un modelo de IA entrenado para analizar el tema de las conversaciones.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        max_tokens=4,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "\n",
        "    response_message = response.choices[0].message.content.strip()\n",
        "    return response_message\n",
        "\n",
        "# Preguntar al usuario qué temas quiere generar\n",
        "temas_usuario = input(\"¿Qué temas quieres generar? (separados por comas) \")\n",
        "\n",
        "# Seleccionar un solo tema de la lista ingresada por el usuario\n",
        "tema_seleccionado = temas_usuario.split(',')[0].strip()\n",
        "\n",
        "# Supongamos que tu DataFrame ya está definido como df\n",
        "df_2 = df.iloc[2260:2278].copy()\n",
        "\n",
        "# Añadir columna 'Theme' al DataFrame\n",
        "df_2['Theme'] = df_2.apply(lambda row: analizar_Theme({\n",
        "    \"structured_conversations\": row['structured_conversations']\n",
        "}, tema_seleccionado), axis=1)\n",
        "\n",
        "print(df_2[['structured_conversations', 'Theme']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCN2-j6SpYaC"
      },
      "source": [
        "# **Input of conversation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64qfSXa2HXGY"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Coversacion:\n",
        "User: hello, I had and issue with my delivery?\n",
        "Assitant:I'm sorry to hear that you've had an issue with your delivery. Can you please provide me with your order number and a brief description of the problem? I'll do my best to assist you.\n",
        "User: the order number is #6572, what can I do?\n",
        "Assistant:Thank you for providing your order number #6572. Let's resolve this issue for you.\n",
        "Verify Order Details: I'll check the status and details of your order.\n",
        "Describe the Issue: Please let me know what specifically went wrong with your delivery (e.g., missing items, wrong items, damaged produce).\n",
        "Resolution Options: Depending on the issue, we can offer various resolutions such as a replacement, a refund, or a discount on your next purchase.\n",
        "Could you please provide more details about the problem with your delivery?\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPw68v5ioELy",
        "outputId": "041b43d3-58d4-4df1-a0b8-ce744693733a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Por favor, ingresa una conversación estructurada:\n",
            "User: hello, I had and issue with my delivery? Assitant:I'm sorry to hear that you've had an issue with your delivery. Can you please provide me with your order number and a brief description of the problem? I'll do my best to assist you. User: the order number is #6572, what can I do? Assistant:Thank you for providing your order number #6572. Let's resolve this issue for you. Verify Order Details: I'll check the status and details of your order. Describe the Issue: Please let me know what specifically went wrong with your delivery (e.g., missing items, wrong items, damaged produce). Resolution Options: Depending on the issue, we can offer various resolutions such as a replacement, a refund, or a discount on your next purchase. Could you please provide more details about the problem with your delivery?\n",
            "                             structured_conversations  \\\n",
            "0   User: when did you purchase this car?\\nAsisten...   \n",
            "1   User: what is special about this car?\\nAsisten...   \n",
            "2   User: Yes, who is the original owner of the ca...   \n",
            "3                                                       \n",
            "4   User: que es un desoto?\\nAsistente: DeSoto es ...   \n",
            "5   User: Hola! Que es un DeSoto\\nAsistente: Hola!...   \n",
            "6                                                       \n",
            "7   User: Hi there\\nAsistente: Hello! How can I as...   \n",
            "8                                                       \n",
            "9   User:  Shayla where are you located?\\nAsistent...   \n",
            "10  User: Hi there, can you tell me more about gre...   \n",
            "11  User: WhatsApp code 584-947\\nAsistente: I apol...   \n",
            "12  User: I live in Miami Beach, when do you deliv...   \n",
            "13  User: “I got zucchini, bed bell peppers and to...   \n",
            "14  User: Tienes tomates earloom?\\nAsistente: Sí, ...   \n",
            "15  User: Test 2\\nAsistente: Hello! How can I assi...   \n",
            "16  User: hola… que vegetales tienes?\\nAsistente: ...   \n",
            "17  User: Yes, I would like to know if you deliver...   \n",
            "18  User: hello, I had and issue with my delivery?...   \n",
            "\n",
            "                        Theme  \n",
            "0              Family History  \n",
            "1              Theme: Vintage  \n",
            "2               Car Ownership  \n",
            "3                         N/A  \n",
            "4                 Car History  \n",
            "5            Automobile Brand  \n",
            "6                         N/A  \n",
            "7        Subscription Service  \n",
            "8                         N/A  \n",
            "9       Green Tomato Business  \n",
            "10  Green Tomato Subscription  \n",
            "11           WhatsApp Support  \n",
            "12          Delivery Schedule  \n",
            "13               Recipe Ideas  \n",
            "14            Product Pricing  \n",
            "15                        N/A  \n",
            "16          Delivery Schedule  \n",
            "17          Delivery Schedule  \n",
            "18             Delivery Issue  \n"
          ]
        }
      ],
      "source": [
        "openai.api_key='####'\n",
        "\n",
        "def analizar_Theme(conversacion):\n",
        "    prompt = f\"\"\"\n",
        "    Eres un modelo de IA especializado en analizar conversaciones.\n",
        "    Tu tarea es identificar el tema principal de una conversación estructurada entre un usuario y un asistente, poniendo especial atención en lo que solicita el usuario.\n",
        "\n",
        "    Por favor, analiza la siguiente conversación y determina el tema principal. El tema debe estar en inglés y ser de 1-3 palabras. Si la conversación está vacía, por favor déjalo en blanco o coloca N/A. No puede incluir la palabra Topic al principio.\n",
        "\n",
        "    Ejemplo 1:\n",
        "    Conversación:\n",
        "    User: Do you have heirloom tomatoes?\n",
        "    Assistant: Yes, we have heirloom tomatoes in our fresh produce selection. You can find them in our mixed fruit and vegetable bags. Subscribe to receive them in your next delivery!\n",
        "    User: How much do they cost?\n",
        "    Assistant: The price of our mixed fruit and vegetable bags varies depending on the size you choose. Our prices range from $XX for the Cherry bag to $XX for the Beefsteak bag. You can find more details about the prices on our website.\n",
        "    Product Pricing\n",
        "\n",
        "    Ejemplo 2:\n",
        "    Conversación:\n",
        "    User: What are your delivery hours?\n",
        "    Assistant: We deliver from 8 AM to 8 PM, Monday through Saturday.\n",
        "    User: Can you deliver on Sunday?\n",
        "    Assistant: Unfortunately, we do not deliver on Sundays.\n",
        "    Delivery Schedule\n",
        "\n",
        "    Ahora analiza la siguiente conversación:\n",
        "\n",
        "    {conversacion['structured_conversations']}\n",
        "    \"\"\"\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Eres un modelo de IA especializado en analizar conversaciones.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        max_tokens=4,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "\n",
        "    response_message = response.choices[0].message.content.strip()\n",
        "    return response_message\n",
        "\n",
        "# Input\n",
        "input_conversation = input(\"Por favor, ingresa una conversación estructurada:\\n\")\n",
        "\n",
        "# Crear un DataFrame con la conversación ingresada\n",
        "data = {\n",
        "    'structured_conversations': [input_conversation]\n",
        "}\n",
        "df_input = pd.DataFrame({'structured_conversations': [input_conversation]})\n",
        "df_existing = df.iloc[2260:2278].copy()\n",
        "df_combined = pd.concat([df_existing, df_input], ignore_index=True)\n",
        "\n",
        "# Añadir columna 'Theme' al DataFrame combinado\n",
        "df_combined['Theme'] = df_combined.apply(lambda row: analizar_Theme({\n",
        "    \"structured_conversations\": row['structured_conversations']\n",
        "}), axis=1)\n",
        "\n",
        "print(df_combined[['structured_conversations', 'Theme']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYVR0X2sYaRn"
      },
      "source": [
        "# **API**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Immetv7HoZF"
      },
      "source": [
        "No esta conectada al df, pero desde postman se le puede hacer un input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SzIUWqqHwbf"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Input:\n",
        "{\n",
        "  \"structured_conversations\": \"User: What are your delivery hours? Assistant: We deliver from 8 AM to 8 PM, Monday through Saturday. User: Can you deliver on Sunday? Assistant: Unfortunately, we do not deliver on Sundays.\"\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "Output:\n",
        "{\n",
        "    \"theme\": \"Delivery Schedule\"\n",
        "}\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfYSGo0aGXZ0",
        "outputId": "9bb3921b-92dd-4c37-a2b0-02db3e10a44a",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.35.3)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.27.0)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.1.4)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.2.1 (from fastapi)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.2->fastapi) (0.12.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (1.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi) (2.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.18.4)\n",
            "Collecting httptools>=0.5.0 (from uvicorn)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (0.1.2)\n",
            "Installing collected packages: websockets, uvloop, uvicorn, ujson, python-multipart, python-dotenv, pyngrok, orjson, httptools, dnspython, watchfiles, starlette, email_validator, fastapi-cli, fastapi\n",
            "Successfully installed dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 httptools-0.6.1 orjson-3.10.5 pyngrok-7.1.6 python-dotenv-1.0.1 python-multipart-0.0.9 starlette-0.37.2 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi uvicorn openai nest_asyncio pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vDCnQ41Wq_81",
        "outputId": "584de35a-1cc8-488b-f4f3-146ac4ddfdbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: NgrokTunnel: \"https://9b2b-34-80-35-202.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [194]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     73.205.34.153:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     73.205.34.153:0 - \"GET /analyze_theme HTTP/1.1\" 307 Temporary Redirect\n",
            "INFO:     73.205.34.153:0 - \"GET /analyze_theme/ HTTP/1.1\" 405 Method Not Allowed\n",
            "INFO:     73.205.34.153:0 - \"GET /analyze_theme HTTP/1.1\" 307 Temporary Redirect\n",
            "INFO:     73.205.34.153:0 - \"GET /analyze_theme/ HTTP/1.1\" 405 Method Not Allowed\n",
            "INFO:     73.205.34.153:0 - \"GET /analyze_theme HTTP/1.1\" 307 Temporary Redirect\n",
            "INFO:     73.205.34.153:0 - \"GET /analyze_theme/ HTTP/1.1\" 405 Method Not Allowed\n",
            "INFO:     73.205.34.153:0 - \"POST /analyze_theme HTTP/1.1\" 307 Temporary Redirect\n",
            "INFO:     73.205.34.153:0 - \"POST /analyze_theme/ HTTP/1.1\" 200 OK\n"
          ]
        }
      ],
      "source": [
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "import openai\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "\n",
        "\n",
        "openai.api_key = '###'\n",
        "ngrok.set_auth_token('###')\n",
        "app = FastAPI()\n",
        "\n",
        "class ConversationRequest(BaseModel):\n",
        "    structured_conversations: str\n",
        "\n",
        "def analizar_Theme(conversacion: str) -> str:\n",
        "    prompt = f\"\"\"\n",
        "    Eres un modelo de IA especializado en analizar conversaciones.\n",
        "    Tu tarea es identificar el tema principal de una conversación estructurada entre un usuario y un asistente, poniendo especial atención en lo que solicita el usuario.\n",
        "\n",
        "    Por favor, analiza la siguiente conversación y determina el tema principal. El tema debe estar en inglés y ser de 1-3 palabras. Si la conversación está vacía, por favor déjalo en blanco o coloca N/A. No puede incluir Topic al principio.\n",
        "\n",
        "    Ejemplo 1:\n",
        "    Conversación:\n",
        "    User: Do you have heirloom tomatoes?\n",
        "    Assistant: Yes, we have heirloom tomatoes in our fresh produce selection. You can find them in our mixed fruit and vegetable bags. Subscribe to receive them in your next delivery!\n",
        "    User: How much do they cost?\n",
        "    Assistant: The price of our mixed fruit and vegetable bags varies depending on the size you choose. Our prices range from $XX for the Cherry bag to $XX for the Beefsteak bag. You can find more details about the prices on our website.\n",
        "    Product Pricing\n",
        "\n",
        "    Ejemplo 2:\n",
        "    Conversación:\n",
        "    User: What are your delivery hours?\n",
        "    Assistant: We deliver from 8 AM to 8 PM, Monday through Saturday.\n",
        "    User: Can you deliver on Sunday?\n",
        "    Assistant: Unfortunately, we do not deliver on Sundays.\n",
        "    Delivery Schedule\n",
        "\n",
        "    Ahora analiza la siguiente conversación:\n",
        "\n",
        "    {conversacion}\n",
        "    \"\"\"\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Eres un modelo de IA entrenado para analizar el tema de las conversaciones.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        max_tokens=4,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "\n",
        "    response_message = response.choices[0].message.content\n",
        "    return response_message\n",
        "\n",
        "@app.post(\"/analyze_theme/\")\n",
        "async def analyze_theme(request: ConversationRequest):\n",
        "    try:\n",
        "        theme = analizar_Theme(request.structured_conversations)\n",
        "        return {\"theme\": theme}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "def run():\n",
        "\n",
        "    public_url = ngrok.connect(addr=\"8000\")\n",
        "    print(f\"Public URL: {public_url}\")\n",
        "    uvicorn.run(app, host='0.0.0.0', port=8000)\n",
        "\n",
        "# Ejecutar el servidor y el túnel ngrok\n",
        "run()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}